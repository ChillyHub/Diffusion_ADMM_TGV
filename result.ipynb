{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import analyzing_tools as at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'sparseview_CT_ADMM_TV_total'\n",
    "config_name = 'AAPM_256_ncsnpp_continuous'\n",
    "\n",
    "method = 'TGV'\n",
    "\n",
    "path_root = f'./results/{config_name}/{problem}/{method}/n_view{8}/rho0_{5}-rho1_{5}-lambda_{0.04}-alpha0_{2.5}-alpha_1_{2.5}/sinogram/'\n",
    "volume_TGV_8views, groud_truth = at.load_volume(path_root, 'recon_198.npy', 'original_198.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 1, 363, 180)\n",
      "(198, 1, 363, 180)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(volume_TGV_8views\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(groud_truth\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 4\u001b[0m result_TGV_8views \u001b[38;5;241m=\u001b[39m at\u001b[38;5;241m.\u001b[39mextract_slices_and_evaluate(volume_TGV_8views, groud_truth)\n\u001b[1;32m      6\u001b[0m aa \u001b[38;5;241m=\u001b[39m result_TGV_8views[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAxial\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSNR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m ab \u001b[38;5;241m=\u001b[39m result_TGV_8views[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAxial\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSIM\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/YanRunyu/Diffusion_ADMM_TGV/analyzing_tools.py:33\u001b[0m, in \u001b[0;36mextract_slices_and_evaluate\u001b[0;34m(volume_reconstructed, volume_reference)\u001b[0m\n\u001b[1;32m     31\u001b[0m slice_reconstructed \u001b[38;5;241m=\u001b[39m volume_reconstructed[z, :, :, :]\n\u001b[1;32m     32\u001b[0m slice_reference \u001b[38;5;241m=\u001b[39m volume_reference[z, :, :, :]\n\u001b[0;32m---> 33\u001b[0m p, s \u001b[38;5;241m=\u001b[39m calculate_metrics(slice_reconstructed, slice_reference)\n\u001b[1;32m     34\u001b[0m psnr_axial\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m     35\u001b[0m ssim_axial\u001b[38;5;241m.\u001b[39mappend(s)\n",
      "File \u001b[0;32m~/Projects/YanRunyu/Diffusion_ADMM_TGV/analyzing_tools.py:18\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(slice_reconstructed, slice_reference)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"calculate PSNR and SSIM for a single slice\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m psnr_value \u001b[38;5;241m=\u001b[39m psnr(slice_reference, slice_reconstructed, data_range\u001b[38;5;241m=\u001b[39mslice_reference\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m slice_reference\u001b[38;5;241m.\u001b[39mmin())\n\u001b[0;32m---> 18\u001b[0m ssim_value \u001b[38;5;241m=\u001b[39m ssim(slice_reference, slice_reconstructed, data_range\u001b[38;5;241m=\u001b[39mslice_reference\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m slice_reference\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m psnr_value, ssim_value\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/skimage/metrics/_structural_similarity.py:178\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m   \u001b[38;5;66;03m# backwards compatibility\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((np\u001b[38;5;241m.\u001b[39masarray(im1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m win_size) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin_size exceeds image extent. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither ensure that your images are \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least 7x7; or pass win_size explicitly \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min the function call, with an odd value \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless than or equal to the smaller side of your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages. If your images are multichannel \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(with color channels), set channel_axis to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe axis number corresponding to the channels.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (win_size \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindow size must be odd.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels."
     ]
    }
   ],
   "source": [
    "print(volume_TGV_8views.shape)\n",
    "print(groud_truth.shape)\n",
    "\n",
    "result_TGV_8views = at.extract_slices_and_evaluate(volume_TGV_8views, groud_truth)\n",
    "\n",
    "aa = result_TGV_8views['Axial']['PSNR']\n",
    "ab = result_TGV_8views['Axial']['SSIM']\n",
    "ba = result_TGV_8views['Coronal']['PSNR']\n",
    "bb = result_TGV_8views['Coronal']['SSIM']\n",
    "ca = result_TGV_8views['Sagittal']['PSNR']\n",
    "cb = result_TGV_8views['Sagittal']['SSIM']\n",
    "\n",
    "print(f'Axial    || Average PSNR: {aa} || Average SSIM: {ab}')\n",
    "print(f'Coronal  || Average PSNR: {ba} || Average SSIM: {bb}')\n",
    "print(f'Sagittal || Average PSNR: {ca} || Average SSIM: {cb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'sparseview_CT_ADMM_TV_total'\n",
    "config_name = 'AAPM_256_ncsnpp_continuous'\n",
    "\n",
    "method = 'TV'\n",
    "\n",
    "path_root = f'./results/{config_name}/{problem}/{method}/n_view{8}/rho_{10}-lambda_{0.04}/sinogram/'\n",
    "volume_TV_8views, groud_truth = at.load_volume(path_root, 'recon_198.npy', 'original_198.npy')\n",
    "\n",
    "path_root = f'./results/{config_name}/{problem}/{method}/n_view{4}/rho_{10}-lambda_{0.04}/sinogram/'\n",
    "volume_TV_4views, _ = at.load_volume(path_root, 'recon_198.npy', 'original_198.npy')\n",
    "\n",
    "path_root = f'./results/{config_name}/{problem}/{method}/n_view{2}/rho_{10}-lambda_{0.04}/sinogram/'\n",
    "volume_TV_2views, _ = at.load_volume(path_root, 'recon_198.npy', 'original_198.npy')\n",
    "\n",
    "method = 'TGV'\n",
    "\n",
    "path_root = f'./results/{config_name}/{problem}/{method}/n_view{8}/rho0_{5}-rho1_{5}-lambda_{0.04}-alpha0_{2.5}-alpha_1_{2.5}/sinogram/'\n",
    "volume_TGV_8views, _ = at.load_volume(path_root, 'recon_198.npy', 'original_198.npy')\n",
    "\n",
    "path_root = f'./results/{config_name}/{problem}/{method}/n_view{4}/rho0_{5}-rho1_{5}-lambda_{0.04}-alpha0_{2.5}-alpha_1_{2.5}/sinogram/'\n",
    "volume_TGV_4views, _ = at.load_volume(path_root, 'recon_198.npy', 'original_198.npy')\n",
    "\n",
    "path_root = f'./results/{config_name}/{problem}/{method}/n_view{2}/rho0_{5}-rho1_{5}-lambda_{0.04}-alpha0_{2.5}-alpha_1_{2.5}/sinogram/'\n",
    "volume_TGV_2views, _ = at.load_volume(path_root, 'recon_198.npy', 'original_198.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_TV_8views = at.extract_slices_and_evaluate(volume_TV_8views, groud_truth)\n",
    "result_TV_4views = at.extract_slices_and_evaluate(volume_TV_4views, groud_truth)\n",
    "result_TV_2views = at.extract_slices_and_evaluate(volume_TV_2views, groud_truth)\n",
    "\n",
    "result_TGV_8views = at.extract_slices_and_evaluate(volume_TGV_8views, groud_truth)\n",
    "result_TGV_4views = at.extract_slices_and_evaluate(volume_TGV_4views, groud_truth)\n",
    "result_TGV_2views = at.extract_slices_and_evaluate(volume_TGV_2views, groud_truth)\n",
    "\n",
    "data_dict_TV = {\n",
    "    '8 views': result_TV_8views,\n",
    "    '4 views': result_TV_4views,\n",
    "    '2 views': result_TV_2views\n",
    "}\n",
    "\n",
    "data_dict_TGV = {\n",
    "    '8 views': result_TGV_8views,\n",
    "    '4 views': result_TGV_4views,\n",
    "    '2 views': result_TGV_2views\n",
    "}\n",
    "\n",
    "dict_list = []\n",
    "dict_list.append(at.flatten_nested_dict(data_dict_TV))\n",
    "dict_list.append(at.flatten_nested_dict(data_dict_TGV))\n",
    "\n",
    "data_df = at.flatten_dicts_to_df(dict_list, ['Diffusion_ADMM_TV', 'Diffusion_ADMM_TGV'])\n",
    "\n",
    "at.table_comparison(data_df, 'PSNR, SSIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.plot_comparison([volume_TV_8views, volume_TGV_8views], ['TV', 'TGV'], groud_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
